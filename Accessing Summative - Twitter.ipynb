{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from rauth import OAuth1Service\n",
    "import os\n",
    "import urllib.parse\n",
    "from auth import TwitterAuth\n",
    "import csv\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950206338411499519\n",
      "getting tweets before 950206338411499519\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 938873956345499653\n",
      "...597 tweets downloaded so far\n",
      "getting tweets before 928926863375794175\n",
      "...797 tweets downloaded so far\n",
      "getting tweets before 921705862992887807\n",
      "...996 tweets downloaded so far\n",
      "getting tweets before 914092750924128261\n",
      "...1196 tweets downloaded so far\n",
      "getting tweets before 907930425657626623\n",
      "...1396 tweets downloaded so far\n",
      "getting tweets before 897878175308546047\n",
      "...1596 tweets downloaded so far\n",
      "getting tweets before 889788202172780543\n",
      "...1796 tweets downloaded so far\n",
      "getting tweets before 880175585418465283\n",
      "...1996 tweets downloaded so far\n",
      "getting tweets before 869170615881793535\n",
      "...2196 tweets downloaded so far\n",
      "getting tweets before 855363343607103488\n",
      "...2396 tweets downloaded so far\n",
      "getting tweets before 838861512999649285\n",
      "...2596 tweets downloaded so far\n",
      "getting tweets before 824968416486387712\n",
      "...2796 tweets downloaded so far\n",
      "getting tweets before 813527932165558272\n",
      "...2995 tweets downloaded so far\n",
      "getting tweets before 797823553244712959\n",
      "...3195 tweets downloaded so far\n",
      "getting tweets before 790621559920615423\n",
      "...3243 tweets downloaded so far\n",
      "getting tweets before 789541345216036863\n",
      "...3243 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "consumer_key = \"nQF1gj31evLAIi7qVL7ePcL0x\"\n",
    "consumer_secret = \"jy9Gwrpv9CpGzSDutQ27tVkLGvQv834oEOKagIyXuraqsHahxb\"\n",
    "access_token = \"2876386222-KS6N4vNj3paunB0ZBHNfgucvcsDgvUt2gKzeiZz\"\n",
    "access_secret = \"btEMNRTGJtxYO8sBHdxSgkYN6DgTrRJ3wkaiXOlW3aYUz\"\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "   \n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    alltweets = []\n",
    "\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200,tweet_mode='extended')\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    print (oldest)\n",
    "\n",
    "    while len(new_tweets) > 0:\n",
    "        print (\"getting tweets before %s\" % (oldest))\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,tweet_mode='extended', max_id=oldest)\n",
    "        alltweets.extend(new_tweets)\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print (\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "        \n",
    "    outtweets = []\n",
    "    \n",
    "    for tweet in alltweets:\n",
    "        keywords = {\"climate\":0, \"environment\":0, \"global warming\":0}\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            if keyword in tweet.full_text.lower():\n",
    "                keywords[keyword]=keywords[keyword]+1\n",
    "                \n",
    "    outtweets = [[screen_name, tweet.id_str, tweet.created_at, tweet.full_text.encode(\"utf-8\"), \\\n",
    "                  tweet.retweet_count, tweet.favorite_count, keywords['climate'],keywords['environment'],keywords['global warming']] \\\n",
    "                 for tweet in alltweets]\n",
    "\n",
    "    with open('dttweets.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"screen_name\",\"id\",\"created_at\",\"text\",\"retweets\", \"favourites\",\"climate\",\"environment\",\"global warming\"])\n",
    "        writer.writerows(outtweets)\n",
    "\n",
    "    pass\n",
    "\n",
    "screen_names = [\"realdonaldtrump\"]\n",
    "for screen_name in screen_names:\n",
    "    get_all_tweets(screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
